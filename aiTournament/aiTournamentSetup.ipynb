{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Tournament\n",
    "\n",
    "This Notebook provides the exact environment setup to be used for the tournament and also shows how submissions will be integrated in it, using the `SubmissionExample` provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import sys, os\n",
    "import time\n",
    "\n",
    "# DIAMBRA Environment related imports\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../')) \n",
    "from makeDiambraEnv import *\n",
    "\n",
    "# Time dependent seed\n",
    "timeDepSeed = int((time.time()-int(time.time()-0.5))*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAMBRA Env kwargs\n",
    "diambraEnvKwargs = {}\n",
    "\n",
    "# DIAMBRA gym kwargs\n",
    "diambraGymKwargs = {}\n",
    "\n",
    "# Wrappers kwargs\n",
    "wrapperKwargs = {}\n",
    "\n",
    "# Additional Observations\n",
    "keyToAdd = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed settings, do not modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAMBRA Env kwargs\n",
    "# Game\n",
    "diambraEnvKwargs[\"gameId\"] = \"doapp\"\n",
    "# Actions frequency (1 every \"mame_diambra_step_ratio\" frames)\n",
    "diambraEnvKwargs[\"mame_diambra_step_ratio\"] = 6\n",
    "# Game difficulty level\n",
    "diambraEnvKwargs[\"difficulty\"] = 3\n",
    "# Number of outfits of the selected character (min 2, max 4)\n",
    "diambraEnvKwargs[\"charOutfits\"] = [2, 2]\n",
    "# 1P game, randomly initialized on P1 or P2 side\n",
    "diambraEnvKwargs[\"player\"] = \"Random\"\n",
    "\n",
    "# Wrappers kwargs\n",
    "# Observations\n",
    "# Frame size\n",
    "wrapperKwargs[\"hwc_obs_resize\"]    = [128, 128, 1]\n",
    "# Number of pixel frames to stack\n",
    "wrapperKwargs[\"frame_stack\"]       = 4\n",
    "# Dilation parameter\n",
    "wrapperKwargs[\"dilation\"]          = 1\n",
    "# Enable/Disable observations scaling\n",
    "wrapperKwargs[\"scale\"]             = True\n",
    "# Select how to scale observation\n",
    "# 0 = Scale frames between 0.0 and 1.0\n",
    "# 1 = Scale frames betweek -1.0 and 1.0\n",
    "wrapperKwargs[\"scale_mod\"]         = 0\n",
    "# Rewards\n",
    "# Enable/Disable rewards normalization\n",
    "wrapperKwargs[\"normalize_rewards\"] = True\n",
    "# Enable/Disable rewards clipping\n",
    "wrapperKwargs[\"clip_rewards\"]      = False\n",
    "\n",
    "# Additional Observations\n",
    "# Last 12 actions, one-hot encoding\n",
    "keyToAdd.append(\"actionsBuf\")\n",
    "# Own and Opponent normalized health value (full bar = 1.0)\n",
    "keyToAdd.append(\"ownHealth\")\n",
    "keyToAdd.append(\"oppHealth\")\n",
    "# Own and Opponent side (left = 0.0, right = 1.0)\n",
    "keyToAdd.append(\"ownPosition\")\n",
    "keyToAdd.append(\"oppPosition\")\n",
    "# Normalized stage (0.0 = first stage, 1.0 = final stage)\n",
    "keyToAdd.append(\"stage\")\n",
    "# Selected character, one-hot encoding \n",
    "keyToAdd.append(\"character\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom settings, modify at will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Path to Repository\n",
    "base_path = \"/home/yourUsername/DIAMBRAenvironment/\"\n",
    "\n",
    "# DIAMBRA Env kwargs\n",
    "# Absolute Path to Diambra Lib\n",
    "diambraEnvKwargs[\"diambraEnv_path\"] = os.path.join(base_path, \"diambraEnvLib/\")\n",
    "# Absolute path to roms\n",
    "diambraEnvKwargs[\"roms_path\"]       = os.path.join(base_path, \"roms/\") \n",
    "# Absolute path to MAME executable\n",
    "diambraEnvKwargs[\"mame_path\"]       = os.path.join(base_path, \"mame/\") \n",
    "\n",
    "# Enable/Disable environment rendering (Disabling it speeds up execution/training)\n",
    "diambraEnvKwargs[\"render\"]      = True\n",
    "# Enable/Disable 60 FPS lock (Disabling it speeds up execution/training)\n",
    "diambraEnvKwargs[\"lock_fps\"]    = True\n",
    "# Enable/Disable Sound\n",
    "diambraEnvKwargs[\"sound\"]       = diambraEnvKwargs[\"lock_fps\"] and diambraEnvKwargs[\"render\"]\n",
    "\n",
    "# Character selection (edit both lists, only first element of them)\n",
    "# Ex 1 (OK): Selecting Kasumi                  = [[\"Kasumi\", \"Random\"], [\"Kasumi\", \"Random\"]]\n",
    "# Ex 2 (OK): Selecting Random Character        = [[\"Random\", \"Random\"], [\"Random\", \"Random\"]]\n",
    "# Ex 3 (KO!): Selecting Gen-Fu only on 1P Side = [[\"Gen-Fu\", \"Random\"], [\"Kasumi\", \"Random\"]]\n",
    "# Available Characters: \n",
    "# Kasumi, Zack, Hayabusa, Bayman, Lei-Fang, Raidou, Gen-Fu, Tina, Bass, Jann-Lee, Ayane\n",
    "diambraEnvKwargs[\"characters\"]  = [[\"Random\", \"Random\"], [\"Random\", \"Random\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter to define behavior when losing 2 rounds\n",
    "#  0.0 = Episode ends\n",
    "#  0.0 < x <= 1.0 = Episode continues x% of the times\n",
    "#  -inf < x < 0.0 = Episode continues int(x) times\n",
    "# !N.B.: evaluation will be carried out with this parameter equal to 0.0!\n",
    "diambraGymKwargs[\"continue_game\"]         = 0.0\n",
    "\n",
    "# Action space definition (only the first element of the two lists influences single player games)\n",
    "# Discrete VS MultiDiscrete                     \n",
    "diambraGymKwargs[\"actionSpace\"]           = [\"discrete\", \"multiDiscrete\"]\n",
    "# Using Attack Buttons Combinations VS Not using them \n",
    "diambraGymKwargs[\"attackButCombinations\"] = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DIAMBRA Environment\n",
    "env = make_diambra_env(diambraGym, env_prefix=\"Test\", seed=timeDepSeed, \n",
    "                       diambra_kwargs=diambraEnvKwargs, diambra_gym_kwargs=diambraGymKwargs,\n",
    "                       wrapper_kwargs=wrapperKwargs, key_to_add=keyToAdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at observation and action spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Observation space\n",
    "print(\"Obs space =\", env.observation_space)\n",
    "print(\"Obs space type =\", env.observation_space.dtype)\n",
    "print(\"Obs space high bound =\", env.observation_space.high)\n",
    "print(\"Obs space low bound =\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing action space\n",
    "print(\"Action space = \", env.action_space)\n",
    "print(\"Action space type = \", env.action_space.dtype)\n",
    "if diambraGymKwargs[\"actionSpace\"][0] == \"multiDiscrete\":\n",
    "    print(\"Action space n = \", env.action_space.nvec)\n",
    "else:\n",
    "    print(\"Action space n = \", env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from submissionExample.agent import agent\n",
    "\n",
    "# Saved model path\n",
    "modelFile = os.path.join(base_path, \"aiTournament/submissionExample/model.pth\")\n",
    "\n",
    "myAgent = agent(agentModel=modelFile, nActions=env.n_actions[0], name=\"Random Agent\", \n",
    "                actionSpace=diambraGymKwargs[\"actionSpace\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute agent policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bookeeping variables for average performance calculation\n",
    "cumulativeEpRew = 0.0\n",
    "cumulativeEpRewAll = []\n",
    "currNumEp = 0\n",
    "\n",
    "# Number of episodes\n",
    "maxNumEp = 10\n",
    "\n",
    "# Resetting the environment\n",
    "observation = env.reset()\n",
    "\n",
    "# Executing the given number of episodes\n",
    "while currNumEp < maxNumEp:\n",
    "\n",
    "    # Agent actions\n",
    "    action = myAgent.act(observation)\n",
    "    print(\"Action:\", action)\n",
    "    \n",
    "    # Stepping the environment\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Updating cumulative reward\n",
    "    cumulativeEpRew += reward\n",
    "    \n",
    "    # Check if episode completed\n",
    "    if np.any(done):\n",
    "        currNumEp += 1\n",
    "        print(\"Ep. # = \", currNumEp)\n",
    "        print(\"Ep. Cumulative Rew # = \", cumulativeEpRew)\n",
    "        cumulativeEpRewAll.append(cumulativeEpRew)\n",
    "        cumulativeEpRew = 0.0\n",
    "\n",
    "        # Resetting the environment\n",
    "        observation = env.reset()\n",
    "\n",
    "print(\"Mean cumulative reward = \", np.mean(cumulativeEpRewAll))    \n",
    "print(\"Std cumulative reward = \", np.std(cumulativeEpRewAll))       \n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
