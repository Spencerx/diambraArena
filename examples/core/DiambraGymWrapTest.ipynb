{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from diambra_environment.makeDiambraEnv import *\n",
    "\n",
    "timeDepSeed = int((time.time()-int(time.time()-0.5))*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_base_path = os.path.join(os.path.abspath(\"\"), \"../../\") # Absolute path to your DIAMBRA environment\n",
    "\n",
    "diambraEnvKwargs = {}\n",
    "diambraEnvKwargs[\"gameId\"]          = \"doapp\"\n",
    "diambraEnvKwargs[\"roms_path\"]       = os.path.join(repo_base_path, \"roms/\") # Absolute path to roms\n",
    "\n",
    "diambraEnvKwargs[\"mame_diambra_step_ratio\"] = 6\n",
    "diambraEnvKwargs[\"render\"]      = True\n",
    "diambraEnvKwargs[\"lock_fps\"]    = True # Locks to 60 FPS\n",
    "diambraEnvKwargs[\"sound\"]       = diambraEnvKwargs[\"lock_fps\"] and diambraEnvKwargs[\"render\"]\n",
    "\n",
    "# 1P\n",
    "diambraEnvKwargs[\"player\"] = \"Random\"\n",
    "# 2P\n",
    "#diambraEnvKwargs[\"player\"] = \"P1P2\"\n",
    "\n",
    "# Game specific\n",
    "diambraEnvKwargs[\"difficulty\"] = 3\n",
    "diambraEnvKwargs[\"characters\"]  = [[\"Random\", \"Random\"], [\"Random\", \"Random\"]]\n",
    "diambraEnvKwargs[\"charOutfits\"] = [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAMBRA gym kwargs\n",
    "diambraGymKwargs = {}\n",
    "diambraGymKwargs[\"P2brain\"]               = None#gamePad_policy\n",
    "diambraGymKwargs[\"continue_game\"]         = 0.0\n",
    "diambraGymKwargs[\"show_final\"]            = False\n",
    "diambraGymKwargs[\"gamePads\"]              = [None, diambraGymKwargs[\"P2brain\"]]\n",
    "diambraGymKwargs[\"actionSpace\"]           = [\"discrete\", \"multiDiscrete\"]\n",
    "diambraGymKwargs[\"attackButCombinations\"] = [True, False]\n",
    "diambraGymKwargs[\"actBufLen\"]             = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrappers kwargs\n",
    "wrapperKwargs = {}\n",
    "wrapperKwargs[\"hwc_obs_resize\"]    = [256, 256, 1]\n",
    "wrapperKwargs[\"normalize_rewards\"] = True\n",
    "wrapperKwargs[\"clip_rewards\"]      = False\n",
    "wrapperKwargs[\"frame_stack\"]       = 6\n",
    "wrapperKwargs[\"dilation\"]          = 1\n",
    "wrapperKwargs[\"scale\"]             = True\n",
    "wrapperKwargs[\"scale_mod\"]         = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Observations\n",
    "\n",
    "#keyToAdd = None\n",
    "\n",
    "keyToAdd = []\n",
    "keyToAdd.append(\"actionsBuf\")\n",
    "\n",
    "if diambraEnvKwargs[\"gameId\"] != \"tektagt\": # DOA, SFIII, UMK3\n",
    "    keyToAdd.append(\"ownHealth\")\n",
    "    keyToAdd.append(\"oppHealth\")\n",
    "else: # TEKTAG\n",
    "    keyToAdd.append(\"ownHealth_1\")\n",
    "    keyToAdd.append(\"ownHealth_2\")\n",
    "    keyToAdd.append(\"oppHealth_1\")\n",
    "    keyToAdd.append(\"oppHealth_2\")\n",
    "\n",
    "keyToAdd.append(\"ownPosition\")\n",
    "keyToAdd.append(\"oppPosition\")\n",
    "#keyToAdd.append(\"ownWins\")\n",
    "#keyToAdd.append(\"oppWins\")\n",
    "keyToAdd.append(\"stage\")\n",
    "keyToAdd.append(\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envId = \"Test\"\n",
    "env = make_diambra_env(diambraGym, env_prefix=envId, seed=timeDepSeed, \n",
    "                       diambra_kwargs=diambraEnvKwargs, \n",
    "                       diambra_gym_kwargs=diambraGymKwargs,\n",
    "                       wrapper_kwargs=wrapperKwargs, \n",
    "                       key_to_add=keyToAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Obs space =\", env.observation_space)\n",
    "print(\"Obs space type =\", env.observation_space.dtype)\n",
    "print(\"Obs space high bound =\", env.observation_space.high)\n",
    "print(\"Obs space low bound =\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing action spaces\n",
    "for idx in range(2):\n",
    "    \n",
    "    if diambraEnvKwargs[\"player\"] != \"P1P2\" and idx == 1:\n",
    "        continue\n",
    "        \n",
    "    print(\"Action space {}P = \".format(idx+1), env.action_spaces[idx])\n",
    "    print(\"Action space type P{} = \".format(idx+1), env.action_spaces[idx].dtype)\n",
    "    if diambraGymKwargs[\"actionSpace\"][idx] == \"multiDiscrete\":\n",
    "        print(\"Action space n = \", env.action_spaces[idx].nvec)\n",
    "    else:\n",
    "        print(\"Action space n = \", env.action_spaces[idx].n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limAct = [None, None]\n",
    "for idx in range(2):\n",
    "    limAct[idx] = [env.actBufLen * env.n_actions[idx][0], \n",
    "                   env.actBufLen * env.n_actions[idx][0] + env.actBufLen * env.n_actions[idx][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Obs content\n",
    "def observationViz(observation, limAct):\n",
    "    \n",
    "        shp = observation.shape\n",
    "        additionalParP1 = int(observation[0,0,shp[2]-1])\n",
    "        print(\"Additional Parameters P1 =\", additionalParP1)\n",
    "        \n",
    "        nScalarAddParP1 = additionalParP1 - len(env.charNames)\\\n",
    "                        - env.actBufLen*(env.n_actions[0][0]+env.n_actions[0][1]) # 1P\n",
    "        print(\"Number of scalar Parameters P1 =\", nScalarAddParP1)\n",
    "        \n",
    "        if diambraEnvKwargs[\"player\"] == \"P1P2\":\n",
    "            additionalParP2 = int(observation[int(shp[0]/2),0,shp[2]-1])\n",
    "            print(\"Additional Parameters P2 =\", additionalParP2)\n",
    "            \n",
    "            nScalarAddParP2 = additionalParP2 - len(env.charNames)\\\n",
    "                            - env.actBufLen*(env.n_actions[1][0]+env.n_actions[1][1])# 2P\n",
    "            print(\"Number of scalar Parameters P2 =\", nScalarAddParP2)\n",
    "        \n",
    "        addPar = observation[:,:,shp[2]-1]\n",
    "        addPar = np.reshape(addPar, (-1))\n",
    "        \n",
    "        # P1\n",
    "        addParP1 = addPar[1:additionalParP1+1]\n",
    "        actionsP1 = addParP1[0:additionalParP1-nScalarAddParP1-env.numberOfCharacters]\n",
    "        \n",
    "        moveActionsP1   = actionsP1[0:limAct[0][0]]\n",
    "        attackActionsP1 = actionsP1[limAct[0][0]:limAct[0][1]]\n",
    "        moveActionsP1   = np.reshape(moveActionsP1, (env.actBufLen,-1))\n",
    "        attackActionsP1 = np.reshape(attackActionsP1, (env.actBufLen,-1))\n",
    "        print(\"Move actions P1 =\\n\", moveActionsP1)\n",
    "        print(\"Attack actions P1 =\\n \", attackActionsP1)\n",
    "        \n",
    "        othersP1 = addParP1[additionalParP1-nScalarAddParP1-env.numberOfCharacters:]\n",
    "        print(\"ownHealthP1 = \", othersP1[0])\n",
    "        print(\"oppHealthP1 = \", othersP1[1])\n",
    "        print(\"ownPositionP1 = \", othersP1[2])\n",
    "        print(\"oppPositionP1 = \", othersP1[3])\n",
    "        print(\"stageP1 = \", othersP1[4])\n",
    "        \n",
    "        print(\"Playing Char P1 = \", env.charNames[list(othersP1[nScalarAddParP1:\n",
    "                                                              nScalarAddParP1 + env.numberOfCharacters]).index(1.0)])\n",
    "      \n",
    "        \n",
    "        # 2P\n",
    "        if diambraEnvKwargs[\"player\"] == \"P1P2\":\n",
    "            addParP2 = addPar[int((shp[0]*shp[1])/2)+1:int((shp[0]*shp[1])/2)+additionalParP2+1]\n",
    "            actionsP2 = addParP2[0:additionalParP2-nScalarAddParP2-env.numberOfCharacters]\n",
    "                        \n",
    "            moveActionsP2   = actionsP2[0:limAct[1][0]]\n",
    "            attackActionsP2 = actionsP2[limAct[1][0]:limAct[1][1]]\n",
    "            moveActionsP2   = np.reshape(moveActionsP2, (env.actBufLen,-1))\n",
    "            attackActionsP2 = np.reshape(attackActionsP2, (env.actBufLen,-1))\n",
    "            print(\"Move actions P2 =\\n\", moveActionsP2)\n",
    "            print(\"Attack actions P2 =\\n\", attackActionsP2)        \n",
    "        \n",
    "            othersP2 = addParP2[additionalParP2-nScalarAddParP2-env.numberOfCharacters:]\n",
    "            print(\"ownHealthP2 = \", othersP2[0])\n",
    "            print(\"oppHealthP2 = \", othersP2[1])\n",
    "            print(\"ownPositionP2 = \", othersP2[2])\n",
    "            print(\"oppPositionP2 = \", othersP2[3])\n",
    "            print(\"stageP1 = \", othersP2[4])\n",
    "  \n",
    "            print(\"Playing Char P2 = \", env.charNames[list(othersP2[nScalarAddParP2:\n",
    "                                                                  nScalarAddParP2 + env.numberOfCharacters]).index(1.0)])\n",
    "        \n",
    "        #input(\"Pause1\")\n",
    "        \n",
    "        obs = np.array(observation).astype(np.float32)\n",
    "    \n",
    "        for idx in range(shp[2]-1):\n",
    "            cv2.imshow(\"image\"+str(idx), obs[:,:,idx])\n",
    "    \n",
    "        cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observationViz(observation, limAct) # Press space bar to complete notebook cell execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulativeEpRew = 0.0\n",
    "cumulativeEpRewAll = []\n",
    "\n",
    "maxNumEp = 100\n",
    "currNumEp = 0\n",
    "\n",
    "while currNumEp < maxNumEp:\n",
    "\n",
    "    # 1P\n",
    "    action = env.action_spaces[0].sample()\n",
    "    \n",
    "    # 2P\n",
    "    action2 = env.action_spaces[1].sample()\n",
    "    if diambraEnvKwargs[\"player\"] == \"P1P2\":\n",
    "        action = np.append(action, action2)\n",
    "\n",
    "    print(\"Action:\", action)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Visualize observations content\n",
    "    print(\"Reward = \", reward)\n",
    "    observationViz(observation, limAct) # Keep space bar pressed to continue env execution\n",
    "        \n",
    "    cumulativeEpRew += reward\n",
    "    \n",
    "    if np.any(done):\n",
    "        currNumEp += 1\n",
    "        print(\"Ep. # = \", currNumEp)\n",
    "        print(\"Ep. Cumulative Rew # = \", cumulativeEpRew)\n",
    "        cumulativeEpRewAll.append(cumulativeEpRew)\n",
    "        cumulativeEpRew = 0.0\n",
    "\n",
    "        observation = env.reset()\n",
    "\n",
    "print(\"Mean cumulative reward = \", np.mean(cumulativeEpRewAll))    \n",
    "print(\"Std cumulative reward = \", np.std(cumulativeEpRewAll))       \n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
